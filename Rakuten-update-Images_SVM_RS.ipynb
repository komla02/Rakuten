{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\anaconda3\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\user\\anaconda3\\lib\\site-packages (0.19.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\anaconda3\\lib\\site-packages (1.4.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (1.9.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (1.21.5)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-image) (2.8.4)\n",
      "Requirement already satisfied: imageio>=2.4.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-image) (2.19.3)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-image) (2021.7.2)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-image) (1.3.0)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-image) (9.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-image) (21.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from packaging>=20.0->scikit-image) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn scikit-image pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "  Using cached imbalanced_learn-0.12.2-py3-none-any.whl (257 kB)\n",
      "Collecting joblib>=1.1.1\n",
      "  Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.21.5)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.9.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from imbalanced-learn) (2.2.0)\n",
      "Installing collected packages: joblib, imbalanced-learn\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.1.0\n",
      "    Uninstalling joblib-1.1.0:\n",
      "      Successfully uninstalled joblib-1.1.0\n",
      "Successfully installed imbalanced-learn-0.12.2 joblib-1.3.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage import io, color, feature, transform\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.utils import class_weight\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des métadonnées\n",
    "X = pd.read_csv(\"C:\\\\Users\\\\user\\\\OneDrive\\\\DATASIENCETEST\\\\PROJET\\\\Data\\\\Update\\\\X_train_update.csv\", index_col=0)\n",
    "y = pd.read_csv(\"C:\\\\Users\\\\user\\\\OneDrive\\\\DATASIENCETEST\\\\PROJET\\\\Data\\\\Update\\\\Y_train_CVw08PX.csv\", index_col=0).squeeze().map(str)\n",
    "X['image_path'] = X.apply(lambda row: os.path.join(\"C:/Users/user/OneDrive/DATASIENCETEST/PROJET/Data/Update/images/image_train\", f'image_{row.imageid}_product_{row.productid}.jpg'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>designation</th>\n",
       "      <th>description</th>\n",
       "      <th>productid</th>\n",
       "      <th>imageid</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Olivia: Personalisiertes Notizbuch / 150 Seite...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3804725264</td>\n",
       "      <td>1263597046</td>\n",
       "      <td>C:/Users/user/OneDrive/DATASIENCETEST/PROJET/D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>436067568</td>\n",
       "      <td>1008141237</td>\n",
       "      <td>C:/Users/user/OneDrive/DATASIENCETEST/PROJET/D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grand Stylet Ergonomique Bleu Gamepad Nintendo...</td>\n",
       "      <td>PILOT STYLE Touch Pen de marque Speedlink est ...</td>\n",
       "      <td>201115110</td>\n",
       "      <td>938777978</td>\n",
       "      <td>C:/Users/user/OneDrive/DATASIENCETEST/PROJET/D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Peluche Donald - Europe - Disneyland 2000 (Mar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50418756</td>\n",
       "      <td>457047496</td>\n",
       "      <td>C:/Users/user/OneDrive/DATASIENCETEST/PROJET/D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>La Guerre Des Tuques</td>\n",
       "      <td>Luc a des id&amp;eacute;es de grandeur. Il veut or...</td>\n",
       "      <td>278535884</td>\n",
       "      <td>1077757786</td>\n",
       "      <td>C:/Users/user/OneDrive/DATASIENCETEST/PROJET/D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84911</th>\n",
       "      <td>The Sims [ Import Anglais ]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>206719094</td>\n",
       "      <td>941495734</td>\n",
       "      <td>C:/Users/user/OneDrive/DATASIENCETEST/PROJET/D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84912</th>\n",
       "      <td>Kit piscine acier NEVADA déco pierre Ø 3.50m x...</td>\n",
       "      <td>&lt;b&gt;Description complète :&lt;/b&gt;&lt;br /&gt;Kit piscine...</td>\n",
       "      <td>3065095706</td>\n",
       "      <td>1188462883</td>\n",
       "      <td>C:/Users/user/OneDrive/DATASIENCETEST/PROJET/D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84913</th>\n",
       "      <td>Journal Officiel De La Republique Francaise N°...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>440707564</td>\n",
       "      <td>1009325617</td>\n",
       "      <td>C:/Users/user/OneDrive/DATASIENCETEST/PROJET/D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84914</th>\n",
       "      <td>Table Basse Bois De Récupération Massif Base B...</td>\n",
       "      <td>&lt;p&gt;Cette table basse a un design unique et con...</td>\n",
       "      <td>3942400296</td>\n",
       "      <td>1267353403</td>\n",
       "      <td>C:/Users/user/OneDrive/DATASIENCETEST/PROJET/D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84915</th>\n",
       "      <td>Gomme De Collection 2 Gommes Pinguin Glace Ver...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57203227</td>\n",
       "      <td>684671297</td>\n",
       "      <td>C:/Users/user/OneDrive/DATASIENCETEST/PROJET/D...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84916 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             designation  \\\n",
       "0      Olivia: Personalisiertes Notizbuch / 150 Seite...   \n",
       "1      Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...   \n",
       "2      Grand Stylet Ergonomique Bleu Gamepad Nintendo...   \n",
       "3      Peluche Donald - Europe - Disneyland 2000 (Mar...   \n",
       "4                                   La Guerre Des Tuques   \n",
       "...                                                  ...   \n",
       "84911                        The Sims [ Import Anglais ]   \n",
       "84912  Kit piscine acier NEVADA déco pierre Ø 3.50m x...   \n",
       "84913  Journal Officiel De La Republique Francaise N°...   \n",
       "84914  Table Basse Bois De Récupération Massif Base B...   \n",
       "84915  Gomme De Collection 2 Gommes Pinguin Glace Ver...   \n",
       "\n",
       "                                             description   productid  \\\n",
       "0                                                    NaN  3804725264   \n",
       "1                                                    NaN   436067568   \n",
       "2      PILOT STYLE Touch Pen de marque Speedlink est ...   201115110   \n",
       "3                                                    NaN    50418756   \n",
       "4      Luc a des id&eacute;es de grandeur. Il veut or...   278535884   \n",
       "...                                                  ...         ...   \n",
       "84911                                                NaN   206719094   \n",
       "84912  <b>Description complète :</b><br />Kit piscine...  3065095706   \n",
       "84913                                                NaN   440707564   \n",
       "84914  <p>Cette table basse a un design unique et con...  3942400296   \n",
       "84915                                                NaN    57203227   \n",
       "\n",
       "          imageid                                         image_path  \n",
       "0      1263597046  C:/Users/user/OneDrive/DATASIENCETEST/PROJET/D...  \n",
       "1      1008141237  C:/Users/user/OneDrive/DATASIENCETEST/PROJET/D...  \n",
       "2       938777978  C:/Users/user/OneDrive/DATASIENCETEST/PROJET/D...  \n",
       "3       457047496  C:/Users/user/OneDrive/DATASIENCETEST/PROJET/D...  \n",
       "4      1077757786  C:/Users/user/OneDrive/DATASIENCETEST/PROJET/D...  \n",
       "...           ...                                                ...  \n",
       "84911   941495734  C:/Users/user/OneDrive/DATASIENCETEST/PROJET/D...  \n",
       "84912  1188462883  C:/Users/user/OneDrive/DATASIENCETEST/PROJET/D...  \n",
       "84913  1009325617  C:/Users/user/OneDrive/DATASIENCETEST/PROJET/D...  \n",
       "84914  1267353403  C:/Users/user/OneDrive/DATASIENCETEST/PROJET/D...  \n",
       "84915   684671297  C:/Users/user/OneDrive/DATASIENCETEST/PROJET/D...  \n",
       "\n",
       "[84916 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction d'extraction des caractéristiques HOG\n",
    "def extract_hog_features(image_path):\n",
    "    image = io.imread(image_path)\n",
    "    image_gray = color.rgb2gray(image)\n",
    "    image_resized = transform.resize(image_gray, (128, 64), anti_aliasing=True)\n",
    "    hog_features = feature.hog(image_resized, pixels_per_cell=(16, 16),\n",
    "                               cells_per_block=(1, 1), visualize=False)\n",
    "    return hog_features\n",
    "\n",
    "# Création du dataset\n",
    "def create_dataset(X, y):\n",
    "    features_list = []\n",
    "    for image_path in X['image_path']:\n",
    "        features = extract_hog_features(image_path)\n",
    "        features_list.append(features)\n",
    "    return np.array(features_list), y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réduction pour des raisons de démonstration\n",
    "sample_X = X.head(50000)\n",
    "sample_y = y.head(50000)\n",
    "\n",
    "X_features, y_labels = create_dataset(sample_X,sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'10': 1794,\n",
       " '1140': 1584,\n",
       " '1160': 2244,\n",
       " '1180': 455,\n",
       " '1280': 2853,\n",
       " '1281': 1193,\n",
       " '1300': 2977,\n",
       " '1301': 454,\n",
       " '1302': 1476,\n",
       " '1320': 1963,\n",
       " '1560': 3054,\n",
       " '1920': 2579,\n",
       " '1940': 440,\n",
       " '2060': 2997,\n",
       " '2220': 490,\n",
       " '2280': 2860,\n",
       " '2403': 2794,\n",
       " '2462': 845,\n",
       " '2522': 2889,\n",
       " '2582': 1495,\n",
       " '2583': 5971,\n",
       " '2585': 1483,\n",
       " '2705': 1648,\n",
       " '2905': 516,\n",
       " '40': 1472,\n",
       " '50': 994,\n",
       " '60': 480}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compter le nombre d'échantillons par classe\n",
    "unique, counts = np.unique(y_labels, return_counts=True)\n",
    "counts_dict = dict(zip(unique, counts))\n",
    "\n",
    "display(counts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rééquilibrage des classes avec SMOTE\n",
    "smote = SMOTE()\n",
    "X_res, y_res = smote.fit_resample(X_features, y_labels)\n",
    "\n",
    "# Division en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'10': 0.9966154345457496,\n",
       " '1140': 0.9889809063722107,\n",
       " '1160': 1.0105305220600334,\n",
       " '1180': 0.9970314710452469,\n",
       " '1280': 0.9914441215811078,\n",
       " '1281': 1.0161195017608546,\n",
       " '1300': 0.9995350026737346,\n",
       " '1301': 1.0050026883605676,\n",
       " '1302': 0.9947475588875005,\n",
       " '1320': 0.9989079418188578,\n",
       " '1560': 1.0020511386150153,\n",
       " '1920': 0.995162037037037,\n",
       " '1940': 1.0086101726726726,\n",
       " '2060': 0.9930930930930931,\n",
       " '2220': 1.0043687505840575,\n",
       " '2280': 0.9939196374901743,\n",
       " '2403': 1.0071216061095885,\n",
       " '2462': 1.0041576156774812,\n",
       " '2522': 0.9964075464701246,\n",
       " '2582': 1.0050026883605676,\n",
       " '2583': 0.9955768607290074,\n",
       " '2585': 1.0001628512935046,\n",
       " '2705': 0.9999534807991999,\n",
       " '2905': 1.00394656952034,\n",
       " '40': 0.9883670138170448,\n",
       " '50': 1.001420917773119,\n",
       " '60': 1.0028926680196888}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Recalcul des poids de classe après rééquilibrage\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced',\n",
    "                                                  classes=np.unique(y_train),\n",
    "                                                  y=y_train)\n",
    "class_weights_dict = {class_label: weight for class_label, weight in zip(np.unique(y_train), class_weights)}\n",
    "\n",
    "display(class_weights_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    }
   ],
   "source": [
    "# Optimisation des hyperparamètres avec RandomizedSearchCV\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'C': [1, 10],\n",
    "    'gamma': ['scale'],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "model = SVC(class_weight=class_weights_dict)\n",
    "\n",
    "# Configuration pour RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(model, param_distributions=param_grid, n_iter=4, cv=3, verbose=1, n_jobs=-1, scoring='accuracy')\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage des meilleurs paramètres et de la meilleure score\n",
    "print(\"Meilleurs paramètres:\", random_search.best_params_)\n",
    "print(\"Meilleur score:\", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Évaluation sur l'ensemble de test\n",
    "y_pred = random_search.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
